{
  "version": "1.0",
  "cells": [
    {
      "type": "markdown",
      "content": "# Deep Learning with Neural Networks\n\nClassical machine learning relies on using statistics to determine relationships between features and labels, and can be very effective for creating predictive models. However, a massive growth in the availability of data coupled with advances in the computing technology required to process it has led to the emergence of new machine learning techniques that mimic the way the brain processes information in a structure called an artificial neural network.\n\nWhile in most \"real-world\" scenarios, you should use a specialist deep learning training framework, like PyTorch; you can use Scikit-Learn to train simple neural network models. In this example, we'll use a neural network to classify wheat seeds into their species based on their measurements.\n\n1. Download [seeds.csv](https://raw.githubusercontent.com/MicrosoftLearning/mslearn-ml-basics/refs/heads/main/Labfiles/data/seeds.csv){:target=\"_blank\"} in a new browser tab, and save it on your local disk.\n2. Then use the **Upload Data** button at the top of this notebook to upload it.\n3. Run the next cell by clicking the **&#9658; Run** button to load the data and train a classification model.\n\n> **Citation**: The seeds dataset used in this exercise was originally published by the Institute of Agrophysics of the Polish Academy of Sciences in Lublin by Dua, D. and Graff, C. (2019). and can be downloaded from the [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml), University of California at Irvine, School of Information and Computer Science."
    },
    {
      "type": "python",
      "content": "import pandas as pd\n\n# load the training dataset\nseeds= pd.read_csv('seeds.csv')\n\n# Display a random sample of 10 observations\nsample = seeds.sample(10)\nprint(sample)"
    },
    {
      "type": "markdown",
      "content": "We'll separate the features from the label, and then split the data into datasets for training and testing"
    },
    {
      "type": "python",
      "content": "from sklearn.model_selection import train_test_split\n\nseed_features = ['area','perimeter','compactness','kernel_length','kernel_width','asymmetry_coefficient','groove_length']\nseed_label = 'species'\n\n# Separate features and labels\nseeds_X, seeds_y = seeds[seed_features].values, seeds[seed_label].values\n\n# Split data 70%-30% into training set and test set\nx_seeds_train, x_seeds_test, y_seeds_train, y_seeds_test = train_test_split(seeds_X, seeds_y,\n                                                                                    test_size=0.30,\n                                                                                    random_state=0,\n                                                                                    stratify=seeds_y)\n\nprint ('Training Set: %d, Test Set: %d \\n' % (x_seeds_train.shape[0], x_seeds_test.shape[0]))"
    },
    {
      "type": "markdown",
      "content": "Now we'll use the MLClassifier algorithm to train a *multi-layer perceptron*, which is a type of neural network. In this case, we'll create a network with three hidden layers, each with 30 neurons."
    },
    {
      "type": "python",
      "content": "from sklearn.neural_network import MLPClassifier\n\nmlp_model = MLPClassifier(hidden_layer_sizes=(30,30,30), activation='relu', learning_rate_init=0.01, learning_rate='adaptive')\nmlp_model.fit(x_seeds_train, y_seeds_train)\n\nprint(mlp_model)"
    },
    {
      "type": "markdown",
      "content": "Now let's evaluate the model with the test data we held back."
    },
    {
      "type": "python",
      "content": "from sklearn. metrics import classification_report\n\nseed_predictions = mlp_model.predict(x_seeds_test)\nprint('Predicted labels: ', seed_predictions[:15])\nprint('Actual labels   : ', y_seeds_test[:15])\n\nprint(\"\\nMetrics:\\n\",classification_report(y_seeds_test, seed_predictions))"
    },
    {
      "type": "markdown",
      "content": "We can also visualize the confusion matrix for our model."
    },
    {
      "type": "python",
      "content": "from sklearn.metrics import confusion_matrix\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nseed_classes = ['Kama Wheat', 'Rosa Wheat', 'Canadian Wheat']\n\n# Plot the confusion matrix\nmcm = confusion_matrix(y_seeds_test, seed_predictions)\nplt.imshow(mcm, interpolation=\"nearest\", cmap=plt.cm.Blues)\nplt.colorbar()\ntick_marks = np.arange(len(seed_classes))\nplt.xticks(tick_marks, seed_classes, rotation=45)\nplt.yticks(tick_marks, seed_classes)\nplt.xlabel(\"Predicted Species\")\nplt.ylabel(\"Actual Species\")\nplt.show()"
    },
    {
      "type": "markdown",
      "content": "The darker squares in the confusion matrix plot indicate high numbers of cases, and you can hopefully see a diagonal line of darker squares indicating cases where the predicted and actual label are the same.\n\nLet's save the model."
    },
    {
      "type": "python",
      "content": "import joblib\n\n# Save the model as a pickle file\nfilename = './mlp_model.pkl'\njoblib.dump(mlp_model, filename)"
    },
    {
      "type": "markdown",
      "content": "Now let's use the model to predict the classes for new seed observations."
    },
    {
      "type": "python",
      "content": "# Load the model from the file\nmlp_model = joblib.load(filename)\n\n# Two new seed observations\nx_new = np.array([[12.73,13.75,0.8458,5.412,2.882,3.533,5.067],\n                  [17.63,15.98,0.8673,6.191,3.561,4.076,6.06]])\nprint ('New samples:\\n{}'.format(x_new))\n\n# Call the web service, passing the input data\npredictions = mlp_model.predict(x_new)\n\n# Get the predicted classes.\nfor prediction in predictions:\n    print(prediction, '(' + seed_classes[prediction] +')')"
    },
    {
      "type": "markdown",
      "content": "## Summary\n\nIn this exercise, you've trained a neural network model to perform classification."
    }
  ]
}